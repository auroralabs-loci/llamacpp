name: Build Project

on:
  pull_request:
    branches: ["**"]
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install dependencies (including curl)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            cmake \
            build-essential \
            gcc-aarch64-linux-gnu \
            g++-aarch64-linux-gnu \
            libcurl4-openssl-dev
     
      - name: Create build directory and configure with CMake
        run: |
          mkdir build
          cd build
          cmake .. -DCMAKE_TOOLCHAIN_FILE=../toolchain-aarch64.cmake -DBUILD_SHARED_LIBS=ON -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_EXAMPLES=OFF -DLLAMA_BUILD_SERVER=OFF


      - name: Build project
        run: |
          cd build
          cmake --build . --target llama -j4
      
      - name: Upload build artifacts
        uses: auroralabs-loci/loci-action@v1.0.1
        env:
          LOCI_BACKEND_URL: '${{ vars.LOCI_DEV_BACKEND_URL }}'
          LOCI_API_KEY: '${{ secrets.LOCI_DEV_AGENTIC_API_KEY }}'
        with:
          mode: upload
          binaries: |
                build/bin/libggml.so
                build/bin/libllama.so
                build/bin/libggml-cpu.so
                build/bin/libggml-base.so
          project: LLaMaCPP_T

      - name: LOCI Summary
        uses: auroralabs-loci/loci-action@v1.0.1
        env:
          LOCI_API_KEY: ${{ secrets.LOCI_DEV_AGENTIC_API_KEY }}
          LOCI_BACKEND_URL: ${{ vars.LOCI_DEV_BACKEND_URL }}
          LOCI_GITHUB_TOKEN: ${{ secrets.LOCI_GITHUB_TOKEN }}
        with:
          mode: summary
          project: LLaMaCPP_T
